---
title: 'Machine Learning System Design'
date: 2025-01-22
permalink: /posts/2025/01/blog-post-2/
tags:
  - machine learning
  - system design
---

This post is a summary of how to design a machine learning system. The content includes the following aspects:

1. Framework
2. Data
3. Feature Engineering
4. Model: Selection and Training
5. Evaluation: Offline and Online
6. Serving

The content is based on the following resources:


# Framework

The first step of designing a machine learning system is to clarify the business objectives. And then we can choose the appropriate framework based on the objectives. There are three common objectives: detection, search and ranking.

## Detection

The objective of detection is to classify the items into different categories. In the machine learning setup, we can compute the embeddings of each item, and use some classifier to classify the items. The corresponding framework is feed-forward computation.

## Search

The objective of search is to find some items that match the query. In the machine learning setup, we can compute embeddings of each search, and use some nearest neighbour service to find the most similar items. The corresponding framework is feed-forward computation.

## Ranking

The objective of ranking is to sort the items based on some criteria. In the machine learning setup, we can compute the embeding of the criteria (user or sessions) and the items, and compute the score based on the embeddings. Finally, the items are sorted based on the scores. The corresponding framework is two-tower computation.

# Data

The key to the machine learning system is the data. There are two kinds of data: user data and item data. User data comes from the user's background and behavior, such as clicks, purchases, and searches. Item data comes from the item's features, such as title, description, category, content, etc. Data can be stored in batch (usually for items and some persistent user information) or comes from stream (user recent behavior). Here are some details:

## User

### Query

This is more related to the search framework. The data will be the search query.

### User profile

This is more related to the ranking framework. The data will be the user's background information, like

1. Demographic information: Age, gender, city, country, language, timezone, etc.
2. Contextual information: Device (OS, browser), Time of the day, etc.
3. Interaction information: 
   1. Ads: Historical click rate, total views, browsing history/session id
   2. News: Mentioned, liked posts ID, shared posts ID, browsing history
   3. E-commerce: Purchase history, browsing history, cart items, wishlist items, etc.
   4. PYMK: School, major, company, start date, end date, etc.

### Inter-user information

This is more related to the ranking framework. The data will be the user's interaction with other users, like

1. Friends: Friends list, when they became friends, etc.
2. User-author interaction: Rate of like, comment, share, etc.
3. Relationship: Family, colleague, etc.

## Item

1. Post: Post ID, author ID, tags, post time, likes, comments, shares, reports, etc.
2. Ads: Ad ID, advertiser ID, ad clicks, total clicks, campaign id, category
3. Event: Location, how many people attended, remaining time, estimated arrival time
4. Video: Video ID, duration, resolution, title, description
5. News: News ID, title, description, category, tags, content, etc.

Beyond the raw data, if we want to train machine learning models in supervised way, we also need corresponding labels. There are several ways to get the labels:

1. Manual labeling: Hire people to label the data
2. Natural labeling: Click means positive, no click means negative, etc
3. Semi-supervised learning: Use some heuristic rules to label the data, apply data augmentation, clustering, etc.

# Feature Engineering

1. Id or categorical: one-hot or look-up embedding
2. Numerical: normalization, standardization, log, etc. Scaling is very important.
3. Text: LLM embeddings, TF-IDF, etc.
4. Image: CNN/ViT embeddings, etc.
5. Video: Get key frames and use CNN/ViT embeddings, Temporal embeding.

# Model: Selection and Training

## Selection
### Baseline

We should always start with a simple model as a baseline. For example, we can use logistic regression for classification, matrix factorization for recommendation.

### NN-based model

1. Compute embeddings for users and items: MLP, CNN, Transformer, etc.
2. Recommendation: Two-tower MLP, DeepFM, GNN, Transformer, etc.

NN-based model can be very versatile and powerful, and proper combination of these blocks can lead to a good model.

## Training

### Loss function

1. Detection: crossentropy loss and MSE
2. Search: Contrastive learning, crossentropy loss
3. Ranking: pointwise-LTR, binary crossentropy loss

### Sampling strategy

In many cases the training labels are highly imbalanced. We can use the following sampling strategies to balance the training data:
1. Over-sampling: Duplicate the minority class, like SMOTE, mixup, etc.
2. Under-sampling: Remove the majority class, like random under-sampling, etc.
3. Online sampling: Use the online sampling strategy, like reservoir sampling, etc.

### Regularization

1. L1, L2 regularization
2. Dropout
3. Batch normalization
4. Early stopping or learning rate decay

## Model Deployment

Some models can be too large to be deployed at fast speed. We can use the following strategies to reduce the model size:
1. Pruning: Remove the unimportant weights
2. Quantization: Reduce the precision of the weights
3. Knowledge distillation: Train a smaller model to mimic the larger model

# Evaluation: Offline and Online

## Offline

1. Detection: Precision, Recall, F1, ROC-AUC (TP-FP), PR-AUC
2. Search & Ranking: Recall@k, MRR, NDCG@k, mAP

## Online

1. Detection: Report rate, Click rate, Prevalence
2. Search & Ranking: CTR, Conversion rate, Revenue, etc.

When deploying, we need to check if the new model is indeed better or working. We can use
1. A/B testing (A/A testing first)
2. Canary release
3. Shadow testing
4. Interleaved experiments (mix the new model with the old model, see which user prefers)

Since real data distribution may change, we need to monitor the model performance and retrain the model periodically, or applying continual learning. We also need to be careful about the catastrophic forgetting problem when using continual learning. Some solutions are 
1. Large dataset to cover everything
2. Domain-invariant representation learning, do not require new labeled data, not widely adopted in industry
3. Current industry practice: retrain the model with new data
   1. Data bucketing: reduce data shift by bucketing the data
   2. Model decoupling: lower frequecy updates for some data, higher frequency updates for some data
   3. Replay buffer: store the old data and mix with the new data
   4. Tweaking optimization: be careful with large gradient updates

# Serving

Serving is the summary of the whole system. This is the pipeline of how the user interacting with the system. The serving system should be fast, reliable, and scalable. The pipeline usually includes the following steps:

## Userless

There is no user, usually for the detection framework. The pipeline is

1. Get the new data
2. Compute the embeddings
3. Apply the system
4. Process item with the results: delete, blur, leave to human, pass, etc.

## User-based

There is a user, usually for the search and ranking framework. 

### Search

1. Get the query
2. Compute the embeddings of the query
3. Approximate the nearest neighbor
4. Post-processing: re-rank, auction, etc.

### Ranking

1. Get the user data or query
2. Compute the embeddings of user
3. Candidate generation: find the candidate items
4. Apply the system to candidate items and user
5. Rank the items
6. Post-processing: re-rank, auction, etc.

Since some of the information does not change rapidly, we can use caching to speed up the serving system. For example, we can cache the embeddings of the items content and tags, user demographic information, and only compute the embeddings of the user activities, query, user-item interaction.
